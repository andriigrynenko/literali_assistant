{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet: ['а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я', 'є', 'і', 'ї', 'ґ']\n",
      "Training data size: 91313\n",
      "Testing data size: 9961\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "dataset_path = \"./dataset0\"\n",
    "\n",
    "characters = os.listdir(dataset_path)\n",
    "characters.sort()\n",
    "print('Alphabet:', characters)\n",
    "\n",
    "def filenames_for_character(character_id):\n",
    "    filenames = os.listdir(dataset_path + '/' + characters[character_id])\n",
    "    filenames.sort()\n",
    "    for filename in filenames:\n",
    "        yield dataset_path + '/' + characters[character_id] + '/' + filename\n",
    "\n",
    "def filenames(epochs=1):\n",
    "    rnd = random.Random()\n",
    "    rnd.seed(0)\n",
    "    for epoch in range(epochs):\n",
    "        res = []\n",
    "        for i in range(len(characters)):\n",
    "            for filename in filenames_for_character(i):\n",
    "                res.append((i, filename))\n",
    "        rnd.shuffle(res)\n",
    "        for filename in res:\n",
    "            yield filename\n",
    "\n",
    "def train_filenames(epochs=1):\n",
    "    for (i, filename) in filenames(epochs):\n",
    "        if filename.endswith('9.png'):\n",
    "            continue\n",
    "        yield (i, filename)\n",
    "\n",
    "def test_filenames():\n",
    "    for (i, filename) in filenames():\n",
    "        if not filename.endswith('9.png'):\n",
    "            continue\n",
    "        yield (i, filename)\n",
    "\n",
    "print('Training data size:', sum(1 for _ in train_filenames()))\n",
    "print('Testing data size:', sum(1 for _ in test_filenames()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=33, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gluk/code/literali_assistant/envs/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/gluk/code/literali_assistant/envs/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import char_net\n",
    "\n",
    "net = char_net.CharNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(net, data):\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    step = 0\n",
    "    running_loss = 0.0\n",
    "    for (input, target) in data:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        step += input.size(dim=0)\n",
    "        if step % 2000 == 0:\n",
    "            print(f'[{step:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def gen_data(filenames):\n",
    "    for (character, img_path) in filenames:\n",
    "        img = Image.open(img_path)\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        img_tensor = transforms.Normalize((torch.mean(img_tensor)), (torch.std(img_tensor)))(img_tensor)\n",
    "\n",
    "        target = torch.zeros(1, dtype=torch.long)\n",
    "        target[0] = character\n",
    "        yield (img_tensor.view((1, 1, 32, 32)), target)\n",
    "\n",
    "def batched_loader(loader, batch_size = 100):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for input, target in loader:\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "        if len(inputs) == batch_size:\n",
    "            yield (torch.cat(inputs, 0), torch.cat(targets, 0))\n",
    "            inputs = []\n",
    "            targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8000] loss: 0.218\n",
      "[16000] loss: 0.205\n",
      "[24000] loss: 0.151\n",
      "[32000] loss: 0.047\n",
      "[40000] loss: 0.015\n",
      "[48000] loss: 0.010\n",
      "[56000] loss: 0.006\n",
      "[64000] loss: 0.005\n",
      "[72000] loss: 0.003\n",
      "[80000] loss: 0.002\n",
      "[88000] loss: 0.003\n",
      "[96000] loss: 0.003\n",
      "[104000] loss: 0.002\n",
      "[112000] loss: 0.002\n",
      "[120000] loss: 0.001\n",
      "[128000] loss: 0.002\n",
      "[136000] loss: 0.001\n",
      "[144000] loss: 0.001\n",
      "[152000] loss: 0.001\n",
      "[160000] loss: 0.001\n",
      "[168000] loss: 0.001\n",
      "[176000] loss: 0.001\n",
      "[184000] loss: 0.002\n",
      "[192000] loss: 0.001\n",
      "[200000] loss: 0.001\n",
      "[208000] loss: 0.001\n",
      "[216000] loss: 0.001\n",
      "[224000] loss: 0.000\n",
      "[232000] loss: 0.000\n",
      "[240000] loss: 0.001\n",
      "[248000] loss: 0.001\n",
      "[256000] loss: 0.002\n",
      "[264000] loss: 0.001\n",
      "[272000] loss: 0.000\n",
      "[280000] loss: 0.000\n",
      "[288000] loss: 0.000\n",
      "[296000] loss: 0.000\n",
      "[304000] loss: 0.001\n",
      "[312000] loss: 0.000\n",
      "[320000] loss: 0.000\n",
      "[328000] loss: 0.001\n",
      "[336000] loss: 0.000\n",
      "[344000] loss: 0.000\n",
      "[352000] loss: 0.000\n",
      "[360000] loss: 0.000\n",
      "[368000] loss: 0.000\n",
      "[376000] loss: 0.000\n",
      "[384000] loss: 0.000\n",
      "[392000] loss: 0.000\n",
      "[400000] loss: 0.001\n",
      "[408000] loss: 0.000\n",
      "[416000] loss: 0.000\n",
      "[424000] loss: 0.000\n",
      "[432000] loss: 0.000\n",
      "[440000] loss: 0.000\n",
      "[448000] loss: 0.000\n",
      "[456000] loss: 0.000\n",
      "[464000] loss: 0.000\n",
      "[472000] loss: 0.000\n",
      "[480000] loss: 0.000\n",
      "[488000] loss: 0.000\n",
      "[496000] loss: 0.000\n",
      "[504000] loss: 0.000\n",
      "[512000] loss: 0.001\n",
      "[520000] loss: 0.000\n",
      "[528000] loss: 0.000\n",
      "[536000] loss: 0.000\n",
      "[544000] loss: 0.000\n",
      "[552000] loss: 0.000\n",
      "[560000] loss: 0.000\n",
      "[568000] loss: 0.000\n",
      "[576000] loss: 0.000\n",
      "[584000] loss: 0.000\n",
      "[592000] loss: 0.000\n",
      "[600000] loss: 0.000\n",
      "[608000] loss: 0.000\n",
      "[616000] loss: 0.000\n",
      "[624000] loss: 0.000\n",
      "[632000] loss: 0.000\n",
      "[640000] loss: 0.000\n",
      "[648000] loss: 0.000\n",
      "[656000] loss: 0.000\n",
      "[664000] loss: 0.000\n",
      "[672000] loss: 0.000\n",
      "[680000] loss: 0.000\n",
      "[688000] loss: 0.000\n",
      "[696000] loss: 0.000\n",
      "[704000] loss: 0.000\n",
      "[712000] loss: 0.000\n",
      "[720000] loss: 0.000\n",
      "[728000] loss: 0.000\n",
      "[736000] loss: 0.000\n",
      "[744000] loss: 0.000\n",
      "[752000] loss: 0.000\n",
      "[760000] loss: 0.000\n",
      "[768000] loss: 0.000\n",
      "[776000] loss: 0.000\n",
      "[784000] loss: 0.000\n",
      "[792000] loss: 0.000\n",
      "[800000] loss: 0.000\n",
      "[808000] loss: 0.000\n",
      "[816000] loss: 0.000\n",
      "[824000] loss: 0.000\n",
      "[832000] loss: 0.000\n",
      "[840000] loss: 0.000\n",
      "[848000] loss: 0.000\n",
      "[856000] loss: 0.000\n",
      "[864000] loss: 0.000\n",
      "[872000] loss: 0.000\n",
      "[880000] loss: 0.000\n",
      "[888000] loss: 0.000\n",
      "[896000] loss: 0.000\n",
      "[904000] loss: 0.000\n",
      "[912000] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs=10\n",
    "train(net, batched_loader(gen_data(train_filenames(epochs)), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected  б  predicted  в\n",
      "Expected  л  predicted  и\n",
      "Expected  з  predicted  і\n",
      "0.9996988254191346\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tests = 0\n",
    "    matches = 0\n",
    "    for (input, target) in gen_data(test_filenames()):\n",
    "        input = input.to(device)\n",
    "        output = net(input)\n",
    "        if torch.max(output ,1)[1] == target[0]:\n",
    "            matches += 1\n",
    "        else:\n",
    "            print('Expected ', characters[target[0]], ' predicted ', characters[torch.max(output, 1)[1]])\n",
    "        tests += 1\n",
    "\n",
    "print(matches / tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'char_net0.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49d3588d25ecea35f7585ee676d10178621ac68dcfe37b4bda18aff4cd275de6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
